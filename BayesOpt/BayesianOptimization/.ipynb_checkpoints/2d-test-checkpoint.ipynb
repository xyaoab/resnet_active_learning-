{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "\n",
    "from torch.distributions.normal import Normal\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import itertools\n",
    "\n",
    "from dimension import Real,Integer, Categorical\n",
    "from bayesian_optimization import BayesianOptimization\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# We use KISS-GP (kernel interpolation for scalable structured Gaussian Processes)# We us \n",
    "# as in https://arxiv.org/pdf/1503.01057.pdf\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Near-zero mean\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-5,5])\n",
    "        # GridInterpolationKernel over an ExactGP\n",
    "        self.base_covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.covar_module = GridInterpolationKernel(self.base_covar_module, grid_size=500,\n",
    "                                                    grid_bounds=[(-10, 10), (-10, 10)])\n",
    "        # Register the log lengthscale as a trainable parametre\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2]])\n",
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#minimize target function\n",
    "def target(x):\n",
    "    return -cos(x[:,0]) * cos(x[:,1]) * np.exp(-(x[:,0] - math.pi)** 2 - (x[:,1] - math.pi)**2)\n",
    "\n",
    "# Training data is 6 points in [-5,15] inclusive regularly spaced\n",
    "\n",
    "x = torch.linspace(-10,10,5)\n",
    "\n",
    "y =  torch.linspace(-10,10,5)\n",
    "# 25 samples \n",
    "train_x = Variable(torch.stack([x.repeat(y.size(0)), y.repeat(x.size(0),1).t().contiguous().view(-1)],1)).cuda()\n",
    "\n",
    "\n",
    "# Maximize the negative target function\n",
    "train_y = Variable(-1*target(train_x)).cuda()\n",
    "\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-8, -7)).cuda()\n",
    "#model = ExactGPModel(train_x.data, train_y.data, likelihood)\n",
    "model = GPRegressionModel(train_x.data, train_y.data, likelihood).cuda()\n",
    "search_space = [Real(-10,10,steps=500),Real(-10,10,steps=500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 1/30 - Loss: 105.164\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 2/30 - Loss: 94.116\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 3/30 - Loss: 84.270\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 4/30 - Loss: 75.479\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 5/30 - Loss: 67.574\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 6/30 - Loss: 60.371\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 7/30 - Loss: 53.675\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 8/30 - Loss: 47.317\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 9/30 - Loss: 41.182\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 10/30 - Loss: 35.292\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 11/30 - Loss: 29.761\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 12/30 - Loss: 24.788\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 13/30 - Loss: 20.557\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 14/30 - Loss: 17.113\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 15/30 - Loss: 14.479\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 16/30 - Loss: 12.422\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 17/30 - Loss: 11.171\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 18/30 - Loss: 10.387\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 19/30 - Loss: 10.740\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 20/30 - Loss: 11.544\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 21/30 - Loss: 12.104\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 22/30 - Loss: 11.289\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 23/30 - Loss: 10.155\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 24/30 - Loss: 9.009\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 25/30 - Loss: 8.299\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 26/30 - Loss: 7.846\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 27/30 - Loss: 7.582\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 28/30 - Loss: 7.421\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 29/30 - Loss: 7.358\n",
      "output torch.Size([25]) train_y torch.Size([25])\n",
      "Iter 30/30 - Loss: 7.294\n"
     ]
    }
   ],
   "source": [
    "#train before optimization\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ], lr=0.1)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 30\n",
    "for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "        # Output from model\n",
    "    output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "    print(\"output\",output.mean().size(), \"train_y\",train_y.size())\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "\n",
    "    print('Iter %d/%d - Loss: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0]\n",
    "        ))\n",
    "  \n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/10 - Loss: 14.374\n",
      "Iter 2/10 - Loss: 12.778\n",
      "Iter 3/10 - Loss: 11.364\n",
      "Iter 4/10 - Loss: 10.473\n",
      "Iter 5/10 - Loss: 9.828\n",
      "Iter 6/10 - Loss: 9.440\n",
      "Iter 7/10 - Loss: 9.275\n",
      "Iter 8/10 - Loss: 9.136\n",
      "Iter 9/10 - Loss: 9.021\n",
      "Iter 10/10 - Loss: 9.002\n",
      "Iter 1/10 - Loss: 12.319\n",
      "Iter 2/10 - Loss: 11.669\n",
      "Iter 3/10 - Loss: 11.155\n",
      "Iter 4/10 - Loss: 10.596\n",
      "Iter 5/10 - Loss: 10.230\n",
      "Iter 6/10 - Loss: 9.993\n",
      "Iter 7/10 - Loss: 9.726\n",
      "Iter 8/10 - Loss: 9.478\n",
      "Iter 9/10 - Loss: 9.266\n",
      "Iter 10/10 - Loss: 9.110\n",
      "Iter 1/10 - Loss: 8.826\n",
      "Iter 2/10 - Loss: 8.671\n",
      "Iter 3/10 - Loss: 8.493\n",
      "Iter 4/10 - Loss: 8.395\n",
      "Iter 5/10 - Loss: 8.185\n",
      "Iter 6/10 - Loss: 8.088\n",
      "Iter 7/10 - Loss: 7.974\n",
      "Iter 8/10 - Loss: 7.838\n",
      "Iter 9/10 - Loss: 7.680\n",
      "Iter 10/10 - Loss: 7.600\n",
      "Iter 1/10 - Loss: 7.786\n",
      "Iter 2/10 - Loss: 7.674\n",
      "Iter 3/10 - Loss: 7.515\n",
      "Iter 4/10 - Loss: 7.377\n",
      "Iter 5/10 - Loss: 7.304\n",
      "Iter 6/10 - Loss: 7.089\n",
      "Iter 7/10 - Loss: 6.986\n",
      "Iter 8/10 - Loss: 6.873\n",
      "Iter 9/10 - Loss: 6.785\n",
      "Iter 10/10 - Loss: 6.673\n",
      "Iter 1/10 - Loss: 6.598\n",
      "Iter 2/10 - Loss: 6.494\n",
      "Iter 3/10 - Loss: 6.388\n",
      "Iter 4/10 - Loss: 6.355\n",
      "Iter 5/10 - Loss: 6.260\n",
      "Iter 6/10 - Loss: 6.185\n",
      "Iter 7/10 - Loss: 6.082\n",
      "Iter 8/10 - Loss: 6.056\n",
      "Iter 9/10 - Loss: 6.069\n",
      "Iter 10/10 - Loss: 6.028\n",
      "Iter 1/10 - Loss: 5.951\n",
      "Iter 2/10 - Loss: 5.897\n",
      "Iter 3/10 - Loss: 5.802\n",
      "Iter 4/10 - Loss: 5.800\n",
      "Iter 5/10 - Loss: 5.742\n",
      "Iter 6/10 - Loss: 5.667\n",
      "Iter 7/10 - Loss: 5.687\n",
      "Iter 8/10 - Loss: 5.660\n",
      "Iter 9/10 - Loss: 5.636\n",
      "Iter 10/10 - Loss: 5.565\n",
      "Iter 1/10 - Loss: 5.556\n",
      "Iter 2/10 - Loss: 5.523\n",
      "Iter 3/10 - Loss: 5.514\n",
      "Iter 4/10 - Loss: 5.488\n",
      "Iter 5/10 - Loss: 5.455\n",
      "Iter 6/10 - Loss: 5.419\n",
      "Iter 7/10 - Loss: 5.418\n",
      "Iter 8/10 - Loss: 5.367\n",
      "Iter 9/10 - Loss: 5.345\n",
      "Iter 10/10 - Loss: 5.342\n",
      "Iter 1/10 - Loss: 5.297\n",
      "Iter 2/10 - Loss: 5.312\n",
      "Iter 3/10 - Loss: 5.278\n",
      "Iter 4/10 - Loss: 5.264\n",
      "Iter 5/10 - Loss: 5.269\n",
      "Iter 6/10 - Loss: 5.245\n",
      "Iter 7/10 - Loss: 5.230\n",
      "Iter 8/10 - Loss: 5.200\n",
      "Iter 9/10 - Loss: 5.168\n",
      "Iter 10/10 - Loss: 5.145\n",
      "Iter 1/10 - Loss: 5.126\n",
      "Iter 2/10 - Loss: 5.133\n",
      "Iter 3/10 - Loss: 5.134\n",
      "Iter 4/10 - Loss: 5.098\n",
      "Iter 5/10 - Loss: 5.085\n",
      "Iter 6/10 - Loss: 5.087\n",
      "Iter 7/10 - Loss: 5.068\n",
      "Iter 8/10 - Loss: 5.015\n",
      "Iter 9/10 - Loss: 5.010\n",
      "Iter 10/10 - Loss: 5.043\n",
      "Iter 1/10 - Loss: 4.994\n",
      "Iter 2/10 - Loss: 4.970\n",
      "Iter 3/10 - Loss: 4.980\n",
      "Iter 4/10 - Loss: 4.966\n",
      "Iter 5/10 - Loss: 4.970\n",
      "Iter 6/10 - Loss: 4.935\n",
      "Iter 7/10 - Loss: 4.958\n",
      "Iter 8/10 - Loss: 4.951\n",
      "Iter 9/10 - Loss: 4.902\n",
      "Iter 10/10 - Loss: 4.916\n"
     ]
    }
   ],
   "source": [
    "bo = BayesianOptimization(model, likelihood,optimizer, target, search_space,\"discrete_mes\")\n",
    "\n",
    "bo.optimal(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [ 2.0040,  2.0040], device='cuda:2')\n",
      "tensor([ 0.1014], device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "print(bo.x_star)\n",
    "print(bo.y_star.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       2.8340, device='cuda:2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(bo.x_star - torch.zeros(1,2).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
