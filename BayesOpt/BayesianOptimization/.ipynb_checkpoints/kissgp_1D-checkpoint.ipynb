{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-68815700f083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbayesian_optimization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/xay2/scripts/BayesOpt/BayesianOptimization/bayesian_optimization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiscrete_mes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscreteMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiscrete_ei\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscreteEI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiscrete_ucb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscreteUCB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "\n",
    "from torch.distributions.normal import Normal\n",
    "from matplotlib import gridspec\n",
    "import itertools\n",
    "\n",
    "from BayesianOptimization.dimension import Real,Integer, Categorical\n",
    "from BayesianOptimization.bayesian_optimization import BayesianOptimization\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use exact GP inference for regression\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-3,3])\n",
    "        # Put a grid interpolation kernel over the RBF kernel\n",
    "        self.base_covar_module = RBFKernel(log_lengthscale_bounds=(-6, 6))\n",
    "        self.covar_module = GridInterpolationKernel(self.base_covar_module, grid_size=400,\n",
    "                                                            grid_bounds=[(0, 1.2)])\n",
    "        # Register kernel lengthscale as parameter\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-6,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Goal: minimize target function\n",
    "def target(x):\n",
    "    #return -1*(3* torch.exp(-(x - 2)**2) + 2*torch.exp(-(x - 6)**2/8) + 1/ (x**2 + 1))\n",
    "    return -(1.4 - 3 * x) * torch.sin(18 * x)\n",
    "\n",
    "\n",
    "train_x = Variable(torch.linspace(0, 1.2, 4)).cuda()\n",
    "\n",
    "# Maximize the negative target function\n",
    "train_y = Variable(-1* target(train_x)).cuda()\n",
    "\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-8, -7)).cuda()\n",
    "model = GPRegressionModel(train_x.data, train_y.data, likelihood).cuda()\n",
    "\n",
    "search_space = [Real(0,1.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train before optimization\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ], lr=0.1)\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 20\n",
    "for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "        # Output from model\n",
    "    output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.data[0]))\n",
    "  \n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(model, likelihood, target, search_space,\"discrete_mes\")\n",
    "\n",
    "bo.optimal(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo.x_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo.y_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
