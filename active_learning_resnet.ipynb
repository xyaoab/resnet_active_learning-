{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import pylab as pl\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython import display\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "import cifarResnet\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import bytescale\n",
    "\n",
    "torch.cuda.set_device(3) # Set gpu number here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR100(root='/data/xay2/cifar100', train=True, download=True)\n",
    "test_set = torchvision.datasets.CIFAR100(root='/data/xay2/cifar100', train=False, download=True)\n",
    "with open('/data/xay2/cifar100/cifar-100-python/train', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "    train_data = d[b'data'].reshape(-1,3,32,32)\n",
    "    train_labels = np.array(d[b'fine_labels'])\n",
    "with open('/data/xay2/cifar100/cifar-100-python/test', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "    testdata = d[b'data'].reshape(-1,3,32,32)\n",
    "    testlabels = np.array(d[b'fine_labels'])\n",
    "    \n",
    "train_size = 40000\n",
    "val_size = 10000\n",
    "traindata = train_data[:train_size]\n",
    "trainlabels = train_labels[:train_size]\n",
    "valdata = train_data[train_size:train_size+val_size]\n",
    "vallabels = train_labels[train_size:train_size + val_size]\n",
    "\n",
    "traindata = torch.Tensor(traindata.astype(np.float64))\n",
    "trainlabels = torch.Tensor(trainlabels.astype(np.float64)).long()\n",
    "valdata = torch.Tensor(valdata.astype(np.float64))\n",
    "vallabels = torch.Tensor(vallabels.astype(np.float64)).long()\n",
    "testdata = torch.Tensor(testdata.astype(np.float64))\n",
    "testlabels = torch.Tensor(testlabels.astype(np.float64)).long()\n",
    "\n",
    "\n",
    "standardize = torchvision.transforms.Normalize(mean=[125.3, 123, 113.9],std=[63, 62.1, 66.7])\n",
    "traindata = torch.cat([standardize(traindata[i]).view(1,3,32,32) for i in range(len(traindata))],dim=0).float()\n",
    "valdata = torch.cat([standardize(valdata[i]).view(1,3,32,32) for i in range(len(valdata))],dim=0).float()\n",
    "testdata = torch.cat([standardize(testdata[i]).view(1,3,32,32) for i in range(len(testdata))],dim=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our helper functions\n",
    "\n",
    "def alter(t):\n",
    "    # flip and crop\n",
    "    if np.random.random(1) > .5:\n",
    "        inv_idx = torch.arange(t.size(2)-1,-1,-1).long()\n",
    "        result = t[:,:,inv_idx]\n",
    "    else:\n",
    "        result = t\n",
    "    result = F.pad(result.view(1,3,32,32),(4,4,4,4)).data\n",
    "    x = np.random.randint(0,high=9)\n",
    "    y = np.random.randint(0,high=9)\n",
    "    return result[0,:,x:x+32,y:y+32].contiguous()\n",
    "\n",
    "def batchmaker(theset, thelabels, shot=100, alterful=False):\n",
    "    batch = np.random.choice(len(theset),shot,replace=False)\n",
    "    data = (torch.cat([alter(theset[i]).view(1,3,32,32) for i in batch],dim=0).float()\n",
    "            if alterful else\n",
    "            torch.cat([theset[i].view(1,3,32,32) for i in batch],dim=0).float())\n",
    "    labels = torch.LongTensor(np.array([thelabels[i] for i in batch]))\n",
    "    \n",
    "    return(Variable(data).cuda(),\n",
    "           Variable(labels).cuda()\n",
    "          )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "def evaluate(model, criterion, testing_data, testing_labels, shot=1000):\n",
    "    support, targs = batchmaker(testing_data, testing_labels, shot=shot)\n",
    "    c = 200\n",
    "    assert shot%c==0\n",
    "    batches = int(shot//c)\n",
    "    support = support.view(batches, c, 3, 32, 32)\n",
    "    targs = targs.view(batches, c)\n",
    "    acc = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(batches):\n",
    "            preds = model(support[i,:,:,:,:])\n",
    "            loss += criterion(preds, targs[i,:]).data[0]\n",
    "            _,bins = torch.max(preds, 1)\n",
    "            acc += torch.sum(torch.eq(bins,targs[i,:])).data[0]\n",
    "    acc = float(acc)/shot\n",
    "    loss = float(loss)/batches\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifarResnet.ResNet(9,16).cuda()\n",
    "i = model.fc.in_features\n",
    "model.fc = nn.Linear(i,100).cuda()\n",
    "#model after fine tuning\n",
    "checkpoint = torch.load('/data/xay2/scripts/pretrained_resnet/fine_tune.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == False:\n",
    "        print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks to drop [4, 5, 1] [3, 2, 5] [2, 7, 1]\n",
      "skip connections 1\n",
      "skip connections 4\n",
      "skip connections 5\n",
      "skip connections 2\n",
      "skip connections 3\n",
      "skip connections 5\n",
      "skip connections 1\n",
      "skip connections 2\n",
      "skip connections 7\n",
      "tensor([ 88,  59,   0,  93,  73,  68,  49,  50,  50,  71,   1,  71,\n",
      "         70,  16,  83,  99,  16,  79,  41,  50,  27,  50,  57,  57,\n",
      "          8,  63,  30,  91,  89,  96,   0,   3,  22,  19,  93,  31,\n",
      "         46,  55,  91,  29,  97,  28,  33,  69,  14,  39,  45,  32,\n",
      "         43,  19], device='cuda:3')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "kl_div_forward is not implemented for type torch.cuda.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-95d9c201beaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: kl_div_forward is not implemented for type torch.cuda.LongTensor"
     ]
    }
   ],
   "source": [
    "batch_data, batch_targets = batchmaker(traindata, trainlabels, alterful=False, shot=50)\n",
    "ensemble = list(range(3))\n",
    "\n",
    "for b in ensemble:\n",
    "    preds = model(batch_data, True)\n",
    "    _,bins = torch.max(preds, 1)\n",
    "    print(bins)\n",
    "    kl = torch.nn.functional.kl_div(bins,batch_targets,True).cuda()\n",
    "\n",
    "print(batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
