{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply active learning on reset\n",
    "## Author: Xinjie Abby Yao, xyaoab@ust.hk\n",
    "## Purpose: reduce # of labelled data to achieve similar accuracy \n",
    "## Dataset: cifar100\n",
    "## Pre-trained model: standard resnet based on cifar10 \n",
    "## Methodolgy: \n",
    "- Skip layers arbitrarily to create a committee \n",
    "- Each member 'votes' on the batch of training images \n",
    "- Apply kl-divgerence (vs mean) to select the most divergent samples\n",
    "- Add those into training batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import pylab as pl\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython import display\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "import cifarResnet\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import bytescale\n",
    "\n",
    "torch.cuda.set_device(1) # Set gpu number here\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR100(root='./cifar100', train=True, download=True)\n",
    "test_set = torchvision.datasets.CIFAR100(root='./cifar100', train=False, download=True)\n",
    "with open('./cifar100/cifar-100-python/train', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "    train_data = d[b'data'].reshape(-1,3,32,32)\n",
    "    train_labels = np.array(d[b'fine_labels'])\n",
    "with open('./cifar100/cifar-100-python/test', 'rb') as fo:\n",
    "    d = pickle.load(fo, encoding='bytes')\n",
    "    testdata = d[b'data'].reshape(-1,3,32,32)\n",
    "    testlabels = np.array(d[b'fine_labels'])\n",
    "    \n",
    "train_size = 40000\n",
    "val_size = 10000\n",
    "traindata = train_data[:train_size]\n",
    "trainlabels = train_labels[:train_size]\n",
    "valdata = train_data[train_size:train_size+val_size]\n",
    "vallabels = train_labels[train_size:train_size + val_size]\n",
    "\n",
    "traindata = torch.Tensor(traindata.astype(np.float64))\n",
    "trainlabels = torch.Tensor(trainlabels.astype(np.float64)).long()\n",
    "valdata = torch.Tensor(valdata.astype(np.float64))\n",
    "vallabels = torch.Tensor(vallabels.astype(np.float64)).long()\n",
    "testdata = torch.Tensor(testdata.astype(np.float64))\n",
    "testlabels = torch.Tensor(testlabels.astype(np.float64)).long()\n",
    "\n",
    "\n",
    "standardize = torchvision.transforms.Normalize(mean=[125.3, 123, 113.9],std=[63, 62.1, 66.7])\n",
    "traindata = torch.cat([standardize(traindata[i]).view(1,3,32,32) for i in range(len(traindata))],dim=0).float()\n",
    "valdata = torch.cat([standardize(valdata[i]).view(1,3,32,32) for i in range(len(valdata))],dim=0).float()\n",
    "testdata = torch.cat([standardize(testdata[i]).view(1,3,32,32) for i in range(len(testdata))],dim=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our helper functions\n",
    "\n",
    "def alter(t):\n",
    "    # flip and crop\n",
    "    if np.random.random(1) > .5:\n",
    "        inv_idx = torch.arange(t.size(2)-1,-1,-1).long()\n",
    "        result = t[:,:,inv_idx]\n",
    "    else:\n",
    "        result = t\n",
    "    result = F.pad(result.view(1,3,32,32),(4,4,4,4)).data\n",
    "    x = np.random.randint(0,high=9)\n",
    "    y = np.random.randint(0,high=9)\n",
    "    return result[0,:,x:x+32,y:y+32].contiguous()\n",
    "\n",
    "def batchmaker(theset, thelabels, shot=100, alterful=False):\n",
    "    batch = np.random.choice(len(theset),shot,replace=False)\n",
    "    data = (torch.cat([alter(theset[i]).view(1,3,32,32) for i in batch],dim=0).float()\n",
    "            if alterful else\n",
    "            torch.cat([theset[i].view(1,3,32,32) for i in batch],dim=0).float())\n",
    "    labels = torch.LongTensor(np.array([thelabels[i] for i in batch]))\n",
    "    \n",
    "    return(Variable(data).cuda(),\n",
    "           Variable(labels).cuda()\n",
    "          )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "def evaluate(model, criterion, testing_data, testing_labels, shot=1000):\n",
    "    support, targs = batchmaker(testing_data, testing_labels, shot=shot)\n",
    "    c = 200\n",
    "    assert shot%c==0\n",
    "    batches = int(shot//c)\n",
    "    support = support.view(batches, c, 3, 32, 32)\n",
    "    targs = targs.view(batches, c)\n",
    "    acc = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(batches):\n",
    "            preds = model(support[i,:,:,:,:])\n",
    "            loss += criterion(preds, targs[i,:]).data[0]\n",
    "            _,bins = torch.max(preds, 1)\n",
    "            acc += torch.sum(torch.eq(bins,targs[i,:])).data[0]\n",
    "    acc = float(acc)/shot\n",
    "    loss = float(loss)/batches\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifarResnet.ResNet(9,16).cuda()\n",
    "i = model.fc.in_features\n",
    "model.fc = nn.Linear(i,100).cuda()\n",
    "#model after fine tuning\n",
    "checkpoint = torch.load('./pretrained_resnet/fine_tune_last_layer.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "for param in model.parameters():\n",
    "    assert param.requires_grad is True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accur=[]\n",
    "def train(data, targets, model):\n",
    "    # Train!\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    vbity = 100\n",
    "    epoch = 200\n",
    "    limit = 800\n",
    "    ensemble = list(range(1)) # Set the number of models that you want to train here\n",
    "    allscores = []\n",
    "    alltrainloss = []\n",
    "    alltestloss = []\n",
    "    start = time.time()\n",
    "    for b in ensemble:\n",
    "        #model = cifarResnet.ResNet(9,16).cuda()\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=.1,weight_decay=.0001,momentum=.9)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x: min(1/(10**(x)),.1))\n",
    "        losstracker = []\n",
    "        evalacctracker = []\n",
    "        evallosstracker = []\n",
    "        runningloss = 0\n",
    "        for it in range(limit):\n",
    "            if it%50==0:\n",
    "                print(it)\n",
    "\n",
    "            # Build batch\n",
    "            support, targs = batchmaker(data, targets, int(targets.size()[0]/3),alterful=True)\n",
    "            model.train()\n",
    "            # Predict\n",
    "            model.zero_grad()\n",
    "            preds = model(support)\n",
    "\n",
    "            # Calculate Loss\n",
    "            loss = criterion(preds, targs)\n",
    "            runningloss += loss.item()\n",
    "\n",
    "            # Backprop\n",
    "            if it%epoch == 0:\n",
    "                scheduler.step()\n",
    "            loss.backward()\n",
    "        #     nn.utils.clip_grad_norm(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Report\n",
    "            if it%vbity == vbity-1:\n",
    "                display.clear_output(wait=True)\n",
    "                print(\"size of train_labels\", targets.size()[0])\n",
    "                print(\"Approximately %.2f hours to completion\"%(\n",
    "                    (time.time()-start)/(it+1+b*limit)*((len(ensemble)-b)*limit-it)/3600))\n",
    "\n",
    "                losstracker.append(runningloss/vbity)\n",
    "                model = model.eval()\n",
    "                evalloss, evalacc = evaluate(model, criterion, valdata, vallabels, shot=10000)\n",
    "                model = model.train()\n",
    "                evallosstracker.append(evalloss)\n",
    "                evalacctracker.append(evalacc)\n",
    "\n",
    "                pl.figure(1,figsize=(15,5))\n",
    "                pl.subplot(1,2,1)\n",
    "                pl.plot(losstracker)\n",
    "                pl.plot(evallosstracker)\n",
    "                pl.ylim((0,1))\n",
    "        #         pl.xlim((0,limit*epoch))\n",
    "                pl.title(\"Loss: Training Blue, Validation Gold\")\n",
    "                pl.subplot(1,2,2)\n",
    "                pl.plot(evalacctracker[::-1])\n",
    "                pl.ylim((0,.2))\n",
    "        #         pl.xlim((0,limit*epoch))\n",
    "                pl.title(\"Validation Acc\")\n",
    "                #pl.show()\n",
    "\n",
    "                print(\"Train loss is: \"+str(runningloss/vbity)+\n",
    "                      \"\\nValidation accuracy is: \"+str(evalacc)+\n",
    "                      \"\\nValidation loss is: \"+str(evalloss)+\"\\n\")\n",
    "                runningloss = 0\n",
    "                #print(allscores)\n",
    "        model.eval()\n",
    "        _,score = evaluate(model, criterion, valdata, vallabels, shot=10000)\n",
    "        allscores.append(score)\n",
    "        alltrainloss.append(losstracker)\n",
    "        alltestloss.append(evallosstracker)\n",
    "\n",
    "    print(\"Average score is\", np.mean(allscores))\n",
    "    train_accur.append(evalacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kl divergence \n",
    "def kld(p,q):\n",
    "    return torch.sum(p * torch.log(p / q) ,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(traindata, trainlabels,shot=800, n_committee=3, k=128*2):    \n",
    "    batch_data, batch_targets = batchmaker(traindata, trainlabels, shot, False)\n",
    "    ensemble = list(range(n_committee))\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds_ensemble = []\n",
    "    for _ in ensemble:\n",
    "        preds = model(batch_data, True)\n",
    "        prob = softmax(preds)\n",
    "        preds_ensemble.append(prob)\n",
    "\n",
    "    preds_ensemble = torch.stack(preds_ensemble)\n",
    "    consensus = (torch.sum(preds_ensemble,dim=0)/len(ensemble))\n",
    "\n",
    "    loss = []\n",
    "    for b in ensemble:\n",
    "        loss.append(kld(preds_ensemble[b], consensus))\n",
    "    loss = torch.stack(loss).sum(dim=0) / len(ensemble)\n",
    "    batch_train_targets = batch_targets[torch.topk(loss, k)[1]]\n",
    "    batch_train_data = batch_data[torch.topk(loss, k)[1]]\n",
    "\n",
    "    return batch_train_data, batch_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_labels 2560\n",
      "Approximately 0.00 hours to completion\n",
      "Train loss is: 0.012303743399679662\n",
      "Validation accuracy is: 0.2016\n",
      "Validation loss is: 6.920519409179687\n",
      "\n",
      "Average score is 0.2016\n",
      "blocks to drop [7, 5, 4] [2, 5] [4]\n",
      "blocks to drop [7, 8, 1] [3, 2] [5]\n",
      "blocks to drop [3, 7, 6] [5, 8] [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAE/CAYAAADVKysfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b993c2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "batch_train_data, batch_train_targets = query(traindata, trainlabels)\n",
    "for _ in range(10):\n",
    "    train(batch_train_data,batch_train_targets,model)\n",
    "    iter_train_data, iter_train_targets = query(traindata, trainlabels)\n",
    "    batch_train_data = torch.cat((batch_train_data, iter_train_data), 0)\n",
    "    batch_train_targets = torch.cat((batch_train_targets, iter_train_targets), 0)\n",
    "train_count = batch_train_targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2816])\n"
     ]
    }
   ],
   "source": [
    "print(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0964, 0.1221, 0.1422, 0.149, 0.1654, 0.1682, 0.1857, 0.1922, 0.2023, 0.2016]\n"
     ]
    }
   ],
   "source": [
    "print(train_accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & Problems \n",
    "- How to avoid selecting the similar batch among each query?\n",
    "- Is each member's opinion distinct enough?\n",
    "- Optimal batch size & query size \n",
    "- Improve code efficiency on selection(reduce runtime)\n",
    "\n",
    "## Insight\n",
    "- Drop more in the first several feature extraction layers \n",
    "- Reduce epoch and iteration to avoid running into similar selection each query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
